{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generations Using n-grams\n",
    "\n",
    "Based on the example https://stackabuse.com/python-for-nlp-developing-an-automatic-text-filler-using-n-grams/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import bs4 as bs\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total number of words: 50661\n\nrobotics is an interdisciplinary research area at the interface of computer science and engineering. robotics involves design, construction, operation, and use of robots. the goal of robotics is to design intelligent machines that can help and assist humans in their day to day lives and keep everyone safe. robotics draws on the achievement of information engineering, computer engineering, mechanical engineering, electronic engineering and others.robotics develops machines that can substitute for humans and replicate human actions. robots can be used in many situations and for many purposes, but today many are used in dangerous environments including inspection of radioactive materials, bomb detection and deactivation, manufacturing processes, or where humans cannot survive e g. in space, underwater, in high heat, and clean up and containment of hazardous materials and radiation. robots can take on any form but some are made to resemble humans in appearance. this is said to help in the \n"
    }
   ],
   "source": [
    "# Read a Wikipedia page and combine all the paragraphs' text\n",
    "articles = [\"Robotics\", \"Artificial_intelligence\", \"Machine_learning\", \"Computer_vision\", \n",
    "            \"Human-robot_interaction\", \"Robotic_sensing\", \"Robotic_sensors\", \"Cyber-physical_system\", \n",
    "            \"Robot_locomotion\", \"Mobile_robot\", \"Robotic_mapping\", \"Robotic_manipulation\"]\n",
    "article_text = \"\"\n",
    "for article_name in articles:\n",
    "    raw_html = urllib.request.urlopen(\"https://en.wikipedia.org/wiki/\" + article_name)\n",
    "    raw_html = raw_html.read()\n",
    "    article_html = bs.BeautifulSoup(raw_html, \"lxml\")\n",
    "    article_paragraphs = article_html.find_all(\"p\")\n",
    "    for para in article_paragraphs:\n",
    "        article_text += para.text\n",
    "\n",
    "# Convert all text to lower case and remove anything besides alphanumerics, some punctuation, and space\n",
    "article_text = article_text.lower()\n",
    "article_text = re.sub(r\"[-]\", \" \", article_text)\n",
    "article_text = re.sub(r\"(?P<n1>[A-Za-z])[^A-za-z ](?P<n2>[A-za-z])\", \"\\g<n1> \\g<n2>\", article_text)\n",
    "article_text = re.sub(r\"[^A-Za-z., ]\", \"\", article_text)\n",
    "\n",
    "# Print the first few words\n",
    "num_words = len(nltk.word_tokenize(article_text))\n",
    "print(\"Total number of words: {}\\n\".format(num_words))\n",
    "print(article_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ", russia ,: ['and']\ncar k in: ['the']\nagents to achieve: ['a']\na competition to: ['sail', 'sail']\nmakes continuous audit: ['possible']\nis an area: ['of', 'of']\nconception , design: [',', ',']\nthe three laws: ['of', 'of', 'of', 'of']\ngoal is to: ['offer', 'successfully', 'memorize', 'learn', 'learn', 'build', 'offer']\nis in contrast: ['to', 'to']\na sequence of: ['facial', 'images', 'facial']\nthe world .: ['finally', 'among', 'applications', 'as', 'finally']\nmoravec s paradox: ['generalizes', 'can', 'suggests']\nth century .: ['throughout', 'the', 'throughout', 'the']\nthe surface of: ['the', 'the', 'the', 'the', 'the', 'the']\n"
    }
   ],
   "source": [
    "# Word n-grams\n",
    "def get_training_ngrams(text, N):\n",
    "    ngrams = {}\n",
    "    words_tokens = nltk.word_tokenize(text)\n",
    "    for i in range(len(words_tokens)-N):\n",
    "        seq = \" \".join(words_tokens[i:i+N])\n",
    "        if seq not in ngrams.keys():\n",
    "            ngrams[seq] = []\n",
    "        ngrams[seq].append(words_tokens[i+N])\n",
    "    return ngrams\n",
    "\n",
    "# Gather n-grams plus the next possible words for completion\n",
    "N = 3\n",
    "ngrams = get_training_ngrams(article_text, N)\n",
    "\n",
    "# Print some random n-grams that have at least 1, 2, and 3 completions\n",
    "num_samples = 5\n",
    "generated_keys = 5\n",
    "for num_completions in range(3):\n",
    "    generated_keys = 0\n",
    "    while generated_keys < num_samples:\n",
    "        key = random.choice(list(ngrams.keys()))\n",
    "        if len(ngrams[key]) > num_completions:\n",
    "            print(\"{}: {}\".format(key, ngrams[key]))\n",
    "            generated_keys += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3-grams:\nrobotics is a conference for scientists , researchers , and practitioners to report and discuss the latest progress of their forefront research and findings in social robotics , had , by , published articles mentioning the subject , and an open access journal called lovotics was launched in , devoted entirely to the subject of computers and art highlighting the role of machine learning , the machine performed a diagnosis similarly to a well trained ophthalmologist , and could generate a decision within seconds on whether or not the speaker has a cold , etc .. it becomes even harder when the speaker\n"
    }
   ],
   "source": [
    "# Predict\n",
    "def generate_sequence(start, ngrams, num_words):\n",
    "    curr_sequence = start.lower()\n",
    "    output = curr_sequence\n",
    "    N = len(list(ngrams.keys())[0].split(\" \"))\n",
    "    for i in range(num_words):\n",
    "        if curr_sequence not in ngrams.keys():\n",
    "            break\n",
    "        possible_words = ngrams[curr_sequence]\n",
    "        next_word = random.choice(possible_words)\n",
    "        output += \" \" + next_word\n",
    "        seq_words = nltk.word_tokenize(output)\n",
    "        curr_sequence = \" \".join(seq_words[len(seq_words)-N:len(seq_words)])\n",
    "    return output\n",
    "\n",
    "start_text = \"Robotics is a\"\n",
    "num_words = 100\n",
    "gen_output = generate_sequence(start_text, ngrams, num_words)\n",
    "\n",
    "print(\"{}-grams:\".format(N))\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2-grams:\ncomputer vision applications , are computing systems vaguely inspired by nature , contributing to climate change mitigation and adaptation , and automatic pilot avionics cps involves transdisciplinary approaches , merging theory of optimization . for example , be made to gain more aerodynamic surface as it navigates its problem space , defence , security , or their ability to feel , does not follow standard research protocol in addition , the rare loyal robots such as space , defence , security , and image restoration is the application of soft computing approaches to ai good old fashioned ai or gofai . during\n"
    }
   ],
   "source": [
    "# Now try with other models\n",
    "N = 2\n",
    "num_words = 100\n",
    "start_text = \"Computer vision\"\n",
    "ngrams = get_training_ngrams(article_text, N)\n",
    "gen_output = generate_sequence(start_text, ngrams, num_words)\n",
    "print(\"{}-grams:\".format(N))\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4-grams:\nmachine learning models require a lot of data in order for them to perform well . usually , when training a machine learning model , one needs to collect a large , representative sample of data from a training set . data from the training set can be as varied as a corpus of text , a collection of images , and data collected from individual users of a service . overfitting is something to watch out for when training a machine learning model.federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process ,\n"
    }
   ],
   "source": [
    "# 4-grams\n",
    "N = 4\n",
    "num_words = 100\n",
    "start_text = \"Machine learning models require\"\n",
    "ngrams = get_training_ngrams(article_text, N)\n",
    "gen_output = generate_sequence(start_text, ngrams, num_words)\n",
    "print(\"{}-grams:\".format(N))\n",
    "print(gen_output)\n",
    "\n",
    "# Funny thing about the paragraph below regarding overfitting\n",
    "# https://en.wikipedia.org/wiki/Machine_learning#Training_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitintronlpconda61e1afdce515499c9770b8779f7d77e0",
   "display_name": "Python 3.6.10 64-bit ('intro-nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}