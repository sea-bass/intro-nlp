{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Rule-Based NLP\n",
    "In this example, we look at basic natural language preprocessing with hand-written rules.\n",
    "\n",
    "## Basic Preprocessing\n",
    "First we will perform typical basic preprocessing on a sentence.\n",
    "\n",
    "The idea is to make it easier to perform downstream processing steps vs. directly using the raw text. For example, we can reduce the number of edge cases in an input sentence (like upper case or special characters), and split it into individual words to it's easier to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to the kitchen, and then get me an apple.\n",
      "['go', 'to', 'the', 'kitchen', 'and', 'then', 'get', 'me', 'an', 'apple']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def preprocess_sentence(raw):\n",
    "    \"\"\" Basic string preprocessing function \"\"\"\n",
    "    # Convert all to lower case\n",
    "    processed = raw.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = processed.translate(\n",
    "        str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Tokenize the sentence by spaces\n",
    "    processed = processed.split(\" \")\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "input_sentence = \"Go to the kitchen, and then get me an apple.\"\n",
    "print(input_sentence)\n",
    "\n",
    "processed_sentence = preprocess_sentence(input_sentence)\n",
    "print(processed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Extraction\n",
    "For simple use cases, we can often get away with directly searching for keywords in a sentence to extract meaning.\n",
    "\n",
    "Suppose we expect the human to speak a sentence that may contain the name of a type of object and a type of location (or room), and we already know the list of objects and rooms beforehand because we have built up that knowledge base manually. This is common in rule-based NLP.\n",
    "\n",
    "Since the processed sentence is already tokenized into a list of individual lowercase words, it is fairly straightforward to do some simple searching in Python to see if a sentence mentions any of the objects and/or locations in our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  Go to the kitchen, and then get me an apple.\n",
      "Target object:   apple\n",
      "Target location: kitchen\n"
     ]
    }
   ],
   "source": [
    "def extract_keywords(words, objects, locations):\n",
    "    \"\"\" \n",
    "    Extracts target objects and locations from a list of words \n",
    "    given lists of possible objects and locations\n",
    "    \"\"\"\n",
    "\n",
    "    target_object = None\n",
    "    target_location = None\n",
    "\n",
    "    # Extract object\n",
    "    for obj in objects:\n",
    "        if obj in words:\n",
    "            target_object = obj\n",
    "            break\n",
    "    \n",
    "    # Extract location\n",
    "    for loc in locations:\n",
    "        if loc in words:\n",
    "            target_location = loc\n",
    "            break\n",
    "\n",
    "    return target_object, target_location\n",
    "\n",
    "\n",
    "input_sentence = \"Go to the kitchen, and then get me an apple.\"\n",
    "objects = [\"apple\", \"water\", \"snacks\"]\n",
    "locations = [\"kitchen\", \"bedroom\", \"garage\"]\n",
    "\n",
    "words = preprocess_sentence(input_sentence)\n",
    "(tgt_obj, tgt_loc) = extract_keywords(words, objects, locations)\n",
    "print(\"Input sentence:  {}\".format(input_sentence))\n",
    "print(\"Target object:   {}\".format(tgt_obj))\n",
    "print(\"Target location: {}\".format(tgt_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Multiple Sentences\n",
    "It is best practice to add some more test cases to our code to check whether it behaves as expected. \n",
    "\n",
    "Specifically, what if the sentence does not mention a valid object and/or location name? What if the human uses a synonymous word, or misspeaks/misspells a word? Would the rule-based system handle this robustly? No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  Go to the kitchen, and then get me an apple\n",
      "Target object:   apple\n",
      "Target location: kitchen\n",
      "\n",
      "Input sentence:  Bring me a bottle of water\n",
      "Target object:   water\n",
      "Target location: None\n",
      "\n",
      "Input sentence:  Drive over to the garage\n",
      "Target object:   None\n",
      "Target location: garage\n",
      "\n",
      "Input sentence:  Find a snack in my bedroom\n",
      "Target object:   None\n",
      "Target location: bedroom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objects = [\"apple\", \"water\", \"snacks\"]\n",
    "locations = [\"kitchen\", \"bedroom\", \"garage\"]\n",
    "input_sentences = [\"Go to the kitchen, and then get me an apple\",\n",
    "                   \"Bring me a bottle of water\", \n",
    "                   \"Drive over to the garage\",\n",
    "                   \"Find a snack in my bedroom\"]\n",
    "\n",
    "for sentence in input_sentences:\n",
    "    words = preprocess_sentence(sentence)\n",
    "    (tgt_obj, tgt_loc) = extract_keywords(words, objects, locations)\n",
    "    print(\"Input sentence:  {}\".format(sentence))\n",
    "    print(\"Target object:   {}\".format(tgt_obj))\n",
    "    print(\"Target location: {}\".format(tgt_loc))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing with Regular Expressions\n",
    "A more robust approach to extract patterns from text is to use regular expressions. Python has a `re` package for regular expressions, and you can refer to [the documentation](https://docs.python.org/3/library/re.html) for more details.\n",
    "\n",
    "Regular expressions allows us to define complex patterns for search-and-replace operations. They have a significant learning curve, but they are undoubtedly useful and worth learning for several applications beyond NLP -- most notably for automating tedious manual tasks by scripting.\n",
    "\n",
    "In the example below, we can use regular expressions to search for the same object and location names without having to preprocess the sentence first. That is, we don't need to split up individual words or remove special characters, which means the regular expression can handle a wider set of human input. We also add a pattern to the object checking logic such that you can enter a singular or plural form (assuming the plural is just the singular word with an `s` in the end, which is not always true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  Go to the kitchen, and then get me an apple\n",
      "Target object:   apple\n",
      "Target location: kitchen\n",
      "\n",
      "Input sentence:  Bring me a BOTTLE OFWATER!!!\n",
      "Target object:   water\n",
      "Target location: None\n",
      "\n",
      "Input sentence:  Drive over to the garage\n",
      "Target object:   None\n",
      "Target location: garage\n",
      "\n",
      "Input sentence:  Find a snack in my bedroom\n",
      "Target object:   snack\n",
      "Target location: bedroom\n",
      "\n",
      "Input sentence:  Look for some apples in the Kitchenette!\n",
      "Target object:   apple\n",
      "Target location: kitchen\n",
      "\n",
      "Input sentence:  Can you search for snacks in the living room?\n",
      "Target object:   snack\n",
      "Target location: living room\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_keywords_regexp(sentence, objects, locations):\n",
    "    \"\"\" \n",
    "    Extracts target objects and locations from a list of words \n",
    "    given lists of possible objects and locations.\n",
    "    This implementation uses regular expressions from the `re` module.\n",
    "    \"\"\"\n",
    "\n",
    "    target_object = None\n",
    "    target_location = None\n",
    "\n",
    "    # Extract object\n",
    "    for obj in objects:\n",
    "        pattern = \"(\" + obj + \")s*\"  # Includes plurals\n",
    "        result = re.search(pattern, sentence, re.IGNORECASE)\n",
    "        if result is not None:\n",
    "            target_object = obj\n",
    "    \n",
    "    # Extract location\n",
    "    for loc in locations:\n",
    "        result = re.search(loc, sentence, re.IGNORECASE)\n",
    "        if result is not None:\n",
    "            target_location = loc\n",
    "\n",
    "    return target_object, target_location\n",
    "\n",
    "\n",
    "objects = [\"apple\", \"water\", \"snack\"]\n",
    "locations = [\"kitchen\", \"bedroom\", \"garage\", \"living room\"]\n",
    "input_sentences = [\"Go to the kitchen, and then get me an apple\",\n",
    "                   \"Bring me a BOTTLE OFWATER!!!\", \n",
    "                   \"Drive over to the garage\",\n",
    "                   \"Find a snack in my bedroom\",\n",
    "                   \"Look for some apples in the Kitchenette!\", \n",
    "                   \"Can you search for snacks in the living room?\"]\n",
    "\n",
    "for sentence in input_sentences:\n",
    "    (tgt_obj, tgt_loc) = extract_keywords_regexp(sentence, objects, locations)\n",
    "    print(\"Input sentence:  {}\".format(sentence))\n",
    "    print(\"Target object:   {}\".format(tgt_obj))\n",
    "    print(\"Target location: {}\".format(tgt_loc))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
