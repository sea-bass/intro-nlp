{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Transformers\n",
    "\n",
    "We will be using the HuggingFace Transformers library: https://github.com/huggingface/transformers\n",
    "\n",
    "This library has great documentation, so please refer to that for more detailed usage after browsing through this simple notebook.\n",
    "\n",
    "To download the library, use `pip` inside your `conda` environment since the `conda-forge` version is quite out of date:\n",
    "\n",
    "```bash\n",
    "pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sample text: Machine learning is the study of computer algorithms that improve automatically through experience.\nHidden states: tensor([[[ 0.0918, -0.6651, -0.5920,  ...,  0.2772, -0.4451,  0.5621],\n         [ 0.3746,  0.4496, -0.4746,  ...,  0.2892,  0.6671,  0.3278],\n         [-0.1143,  0.4511, -0.6710,  ..., -0.5707, -0.0513,  0.6873],\n         ...,\n         [-0.1761, -0.0033,  0.0998,  ..., -0.9533, -0.9809,  0.2631],\n         [ 0.8583,  0.0425, -0.4340,  ...,  0.0977, -0.7423, -0.0583],\n         [ 0.6726,  0.0225, -0.1304,  ...,  0.2195, -0.8982, -0.1860]]])\nHidden states shape: torch.Size([1, 16, 768])\nAttentions shape: torch.Size([1, 768])\n"
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name,\n",
    "                                          output_hidden_states=True,\n",
    "                                          output_attentions=True)\n",
    "                                          \n",
    "sample_text = \"Machine learning is the study of computer algorithms that improve automatically through experience.\"\n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(sample_text, add_special_tokens=True)])\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    hidden_states = outputs[0]\n",
    "    attentions = outputs[1]\n",
    "\n",
    "print(\"Sample text: {}\".format(sample_text))\n",
    "print(\"Hidden states: {}\".format(hidden_states))\n",
    "print(\"Hidden states shape: {}\".format(hidden_states.shape))\n",
    "print(\"Attentions shape: {}\".format(attentions.shape))\n",
    "\n",
    "del(model)\n",
    "del(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Example: Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 230/230 [00:00<00:00, 80.0kB/s]\n\nQuestion: When was RoboCup founded?\nAnswer: 1996\nScore: 0.9921742685001611\n\nQuestion: Who is the president of RoboCup?\nAnswer: Peter Stone\nScore: 0.994986112397072\n\nQuestion: Where was the 2019 RoboCup international competition held?\nAnswer: Sydney, Australia.\nScore: 0.8968013221865334\n\nQuestion: What is the main goal of RoboCup?\nAnswer: to promote robotics and AI research\nScore: 0.4689098121865669\n"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "context = \"\"\"\n",
    "RoboCup is an annual international robotics competition proposed and founded in 1996 by a group of university professors (including Hiroaki Kitano, Manuela M. Veloso, and Minoru Asada). The aim of the competition is to promote robotics and AI research by offering a publicly appealing – but formidable – challenge. \n",
    "The name RoboCup is a contraction of the competition's full name, \"Robot Soccer World Cup\", but there are many other areas of competition such as \"RoboCupRescue\", \"RoboCup@Home\" and \"RoboCupJunior\". In 2019, the international competition was held in Sydney, Australia. Peter Stone is the current president of RoboCup, and has been since 2019.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"When was RoboCup founded?\",\n",
    "    \"Who is the president of RoboCup?\",\n",
    "    \"Where was the 2019 RoboCup international competition held?\",\n",
    "    \"What is the main goal of RoboCup?\"\n",
    "]\n",
    "\n",
    "model_name = \"bert-large-cased-whole-word-masking-finetuned-squad\"\n",
    "nlp_qa = pipeline(\"question-answering\", \n",
    "                  model=model_name, \n",
    "                  tokenizer=model_name,\n",
    "                  framework=\"pt\")\n",
    "\n",
    "for question in questions:\n",
    "    result = nlp_qa(question=question, context=context)\n",
    "    answer = result[\"answer\"]\n",
    "    score = result[\"score\"]\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Question: {}\".format(question))\n",
    "    print(\"Answer: {}\".format(answer))\n",
    "    print(\"Score: {}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitintronlpconda61e1afdce515499c9770b8779f7d77e0",
   "display_name": "Python 3.6.10 64-bit ('intro-nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}