{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Classification Using Recurrent Neural Nets (RNNs)\n",
    "\n",
    "In this example, we will use PyTorch to classify sentences in the form of commands to a robot. For example:\n",
    "\n",
    "```Find a red apple near the kitchen area```\n",
    "\n",
    "Should return 3 output labels:\n",
    "* Action: Find\n",
    "* Room: Kitchen\n",
    "* Object: Apple\n",
    "\n",
    "This is therefore a 3-output multi-class classification problem. We will first encode our sentences using pretrained [GloVe word vectors](https://nlp.stanford.edu/projects/glove/) and then pass them through a Recurrent Neural Network (RNN) defined in [PyTorch](https://pytorch.org/).\n",
    "\n",
    "This example based on work at MIT CSAIL by Sebastian Castro, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as func\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 0\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word Embeddings and Data\n",
    "\n",
    "You will first need to download [GloVe vectors from the Stanford Web page](https://nlp.stanford.edu/projects/glove/). \n",
    "\n",
    "As you will see, there are various sizes of feature vectors that were trained on different sized corpora. For this example, we will download the \"smallest\" set of vectors which were trained on 6 billion tokens -- which are labeled as `glove.6B`.\n",
    "\n",
    "1. Download the data from [this link](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "2. Extract the downloaded ZIP file to the folder containing this notebook, so that you have a `glove.6B` folder at the same level as the notebook.\n",
    "\n",
    "You will see that these are 4 different files in the folder -- tagged with the prefixes `50d`, `100d`, `200d`, and `300d`. These correspond to the embedding vector dimensions. The smaller vector sizes will take up much less memory when training and using a model, but will have less representational capacity. You should try different vector sizes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embeddings(file_name, max_words=50000):\n",
    "    \"\"\"\n",
    "    Read word vectors and create conversion dictionaries from a word embeddings file\n",
    "    Optionally, you can change the number of maximum words to use\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the dictionaries with the unknown token\n",
    "    word_to_ix = {\"<UNK>\": 0}\n",
    "    ix_to_word = {0: \"<UNK>\"}\n",
    "    vectors = [[]]\n",
    "\n",
    "    # Go through all the words, get their embedding vectors, and add to the dictionaries\n",
    "    with open(file_name,\"r\") as f:\n",
    "        counter = 0\n",
    "        for line in f.readlines():\n",
    "            items = line.split()\n",
    "            if counter < max_words:\n",
    "                counter += 1\n",
    "                word_to_ix[items[0]] = counter\n",
    "                ix_to_word[counter] = items[0]\n",
    "                vectors.append([float(x) for x in items[1:]])\n",
    "\n",
    "        # Randomly set the weights of the first element mapping to \"UNKNOWN\"\n",
    "        vector_len = len(vectors[-1])\n",
    "        vectors[0] = [np.random.random() * 2.0 - 1.0\n",
    "                        for _ in range(vector_len)]\n",
    "\n",
    "    return np.array(vectors), word_to_ix, ix_to_word\n",
    "\n",
    "\n",
    "def prepare_input_sequence(sentence, word_to_ix):\n",
    "    \"\"\" Uses the word to index dictionary to create a sequence of vocabulary indices \"\"\"\n",
    "    \n",
    "    # Convert sentence to lower case, remove punctuation, and split\n",
    "    sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    seq = sentence.lower().split(\" \")\n",
    "    \n",
    "    # Now convert to a word index\n",
    "    indices = []\n",
    "    for w in seq:\n",
    "        try:\n",
    "            idx = word_to_ix[w]\n",
    "        except:\n",
    "            idx = 0 # UNK token\n",
    "        indices.append(idx)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def prepare_target_sequence(seq, action_to_ix, room_to_ix, obj_to_ix):\n",
    "    \"\"\"\n",
    "    Uses the output grounding target dictionaries to create a sequence of output indices\n",
    "    \"\"\"\n",
    "    action_idxs = [action_to_ix[seq[0]]]\n",
    "    room_idxs = [room_to_ix[seq[1]]]\n",
    "    object_idxs = [obj_to_ix[seq[2]]]\n",
    "    return action_idxs, room_idxs, object_idxs\n",
    "\n",
    "\n",
    "glove_file = os.path.join(\"glove.6B\", \"glove.6B.100d.txt\") # Modify this as needed\n",
    "glove_vectors, w2i, i2w = load_embeddings(glove_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a PyTorch Dataset\n",
    "\n",
    "PyTorch offers various utilities for connecting your data to a neural network based training and/or inference pipeline. These are specifically \n",
    "\n",
    "* **Datasets** for managing the data and loading individual items\n",
    "* **Dataloaders** for handling dataset-wide utilities like shuffling, batching, etc.\n",
    "* **Transforms** for applying run-time transformations and/or data augmentation techniques to the data\n",
    "\n",
    "Refer to [this PyTorch tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for more information.\n",
    "\n",
    "For simplicity, this example only uses a *dataset*, which means that it cannot be directly used to train and infer on batches of data. We will do all training and inference one text sequence at a time, which certainly slows things down but hopefully makes it easier to follow the example.\n",
    "\n",
    "The data itself can be found in the `data` folder, namely in the [`rnn_training_data.txt`](data/rnn_training_data.txt) and [`rnn_test_data.txt`](data/rnn_test_data.txt). You can also randomly generate your own dataset using the [`generate_rnn_data.py`](data/generate_rnn_data.py) script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Action</th>\n",
       "      <th>Room</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>move by the cookies by the parlor</td>\n",
       "      <td>go</td>\n",
       "      <td>living room</td>\n",
       "      <td>snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fetch a chips inside the my room</td>\n",
       "      <td>get</td>\n",
       "      <td>bedroom</td>\n",
       "      <td>snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean up the apple from the living room</td>\n",
       "      <td>store</td>\n",
       "      <td>living room</td>\n",
       "      <td>fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>locate some water from the bedroom</td>\n",
       "      <td>find</td>\n",
       "      <td>bedroom</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean up an item from the pantry</td>\n",
       "      <td>store</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>put back a thing in the canteen</td>\n",
       "      <td>store</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>find me an item near the parlor</td>\n",
       "      <td>find</td>\n",
       "      <td>living room</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>go near the chips</td>\n",
       "      <td>go</td>\n",
       "      <td>unknown</td>\n",
       "      <td>snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>bring a beverage close to the pantry</td>\n",
       "      <td>get</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>throw away a banana by the pantry</td>\n",
       "      <td>store</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Sentence Action         Room   Object\n",
       "0          move by the cookies by the parlor     go  living room    snack\n",
       "1           fetch a chips inside the my room    get      bedroom    snack\n",
       "2    clean up the apple from the living room  store  living room    fruit\n",
       "3         locate some water from the bedroom   find      bedroom    drink\n",
       "4           clean up an item from the pantry  store      kitchen  unknown\n",
       "..                                       ...    ...          ...      ...\n",
       "995          put back a thing in the canteen  store      kitchen  unknown\n",
       "996          find me an item near the parlor   find  living room  unknown\n",
       "997                        go near the chips     go      unknown    snack\n",
       "998     bring a beverage close to the pantry    get      kitchen    drink\n",
       "999        throw away a banana by the pantry  store      kitchen    fruit\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get me some banana by the bedroom\n",
      "\n",
      "Word indices:\n",
      "tensor([  170,   286,    78, 10706,    22,     1,  7093])\n",
      "\n",
      "Target indices:\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "class GroundingDataset(Dataset):\n",
    "    \"\"\" Language grounding dataset \"\"\"\n",
    "\n",
    "    def __init__(self, filename, word_to_ix, action_to_ix, room_to_ix, object_to_ix, transform=None):\n",
    "        self.data = pd.read_table(filename, sep=\",\")\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.action_to_ix = action_to_ix\n",
    "        self.room_to_ix = room_to_ix\n",
    "        self.object_to_ix = object_to_ix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        item = self.data.iloc[idx].to_dict()\n",
    "        inp_seq = item[\"Sentence\"]\n",
    "        inp = prepare_input_sequence(inp_seq, self.word_to_ix)\n",
    "        tgt_seq = (item[\"Action\"], item[\"Room\"], item[\"Object\"])\n",
    "        tgt = prepare_target_sequence(tgt_seq,\n",
    "            self.action_to_ix, self.room_to_ix, self.object_to_ix)\n",
    "\n",
    "        return torch.LongTensor(inp), torch.LongTensor(tgt)\n",
    "\n",
    "    def get_sentence(self, idx):\n",
    "        return self.data[\"Sentence\"][idx]\n",
    "\n",
    "    def print_dataset(self):\n",
    "        display(self.data) # If not in a Jupyter notebook, use print(self.data)\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "def create_grounding_dict(grounding_list):\n",
    "    \"\"\"\n",
    "    Creates a grounding dictionary from a list. For example:\n",
    "        [\"Find,\"Go\",\"Get\",\"Store\"]\n",
    "    becomes\n",
    "        {\"Find\":0, \"Get\":1, \"Go\":2, \"Store\":3}\n",
    "    \"\"\"\n",
    "\n",
    "    idx = 0\n",
    "    grounding_dict = {}\n",
    "    for elem in grounding_list:\n",
    "        grounding_dict[elem] = idx\n",
    "        idx += 1\n",
    "\n",
    "    return grounding_dict\n",
    "\n",
    "\n",
    "def create_target_dictionaries(training_file):\n",
    "    \"\"\"\n",
    "    Create dictionaries for all the outputs (targets) of the grounding network\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the training data and get sorted list of all the groundings\n",
    "    data = pd.read_table(training_file,sep=\",\")\n",
    "    action_list = sorted(set(data.Action))\n",
    "    room_list = sorted(set(data.Room))\n",
    "    object_list = sorted(set(data.Object))\n",
    "\n",
    "    # Convert to dictionary that is compatible with the grounding model\n",
    "    action_to_ix = create_grounding_dict(action_list)\n",
    "    room_to_ix = create_grounding_dict(room_list)\n",
    "    object_to_ix = create_grounding_dict(object_list)\n",
    "    return action_to_ix, room_to_ix, object_to_ix\n",
    "\n",
    "# Create the training and test datasets\n",
    "training_file = os.path.join(\"data\", \"rnn_training_data.txt\")\n",
    "test_file = os.path.join(\"data\", \"rnn_test_data.txt\")\n",
    "act2i, room2i, obj2i = create_target_dictionaries(training_file)\n",
    "training_data = GroundingDataset(training_file, w2i, act2i, room2i, obj2i)\n",
    "test_data = GroundingDataset(test_file, w2i, act2i, room2i, obj2i)\n",
    "\n",
    "# Print the training dataset, which internally stores data as a Pandas table\n",
    "training_data.print_dataset()\n",
    "\n",
    "# Get a random item from the training data and view its PyTorch-compatible representation\n",
    "idx = np.random.randint(0, training_data.__len__())\n",
    "print(training_data.get_sentence(idx))\n",
    "item = training_data.__getitem__(idx)\n",
    "print(\"\\nWord indices:\\n{}\".format(item[0]))\n",
    "print(\"\\nTarget indices:\\n{}\".format(item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Recurrent Neural Network (RNN) Architecture\n",
    "\n",
    "Now that we covered the important supporting part of getting our data loaded as PyTorch Tensors, we finally get to the \"fun\" part which is defining the neural network architecture. The class below has several options for modifying the network sizes and structure. The important parameters are:\n",
    "\n",
    "* `unit_type` - Can be `rnn` (\"vanilla RNN\" with `tanh` activation), `gru` (Gated Recurrent Unit), or `lstm` (Long-Short Term Memory)\n",
    "* `bidir` - Set to `True` or `False` for bidirectionality\n",
    "* `hidden_dim` - The hidden dimension of each recurrent unit\n",
    "* `num_layers` - Number of total recurrent layers\n",
    "\n",
    "As mentioned earlier, this will work only by passing individual inputs or batches of fixed-size sequences, as it makes the syntax simpler.\n",
    "\n",
    "If you want to use batches of data with variable-size sequences, you may want to look at the [`pad_packed_sequence`](https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pad_packed_sequence.html) and [`pack_padded_sequence`](https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pack_padded_sequence.html) functions. You can also follow [this tutorial by suzyahyah](https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundingNetwork(\n",
      "  (word_embeddings): Embedding(50001, 100)\n",
      "  (recurrent): RNN(100, 32, num_layers=2, batch_first=True, dropout=0.25)\n",
      "  (hidden2action): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (hidden2room): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (hidden2object): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Sentence: Go to the kitchen and find an apple.\n",
      "Word Sequence: [243, 5, 1, 4907, 6, 597, 30, 3293]\n",
      "\n",
      "Action scores: [[0.27299276 0.21096526 0.2631889  0.25285307]]\n",
      "Room scores: [[0.23197006 0.31811956 0.23808897 0.21182136]]\n",
      "Object scores: [[0.29734012 0.1590196  0.20281453 0.34082583]]\n"
     ]
    }
   ],
   "source": [
    "class GroundingNetwork(nn.Module):\n",
    "    \"\"\"Neural network for language grounding\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, room_size, object_size,\n",
    "                 unit_type=\"rnn\", hidden_dim=32, num_layers=2, \n",
    "                 emb_weights=glove_vectors, bidir=False, dropout=0.25):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set dimension of hidden layer depending on LSTM directionality\n",
    "        if bidir:\n",
    "            self.hidden_dim = hidden_dim * 2\n",
    "        else:\n",
    "            self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Initialize word embeddings from the pretrained vectors and freeze the weights\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(torch.Tensor(emb_weights), freeze=True)\n",
    "        (_, embedding_dim) = emb_weights.shape\n",
    "\n",
    "        # The RNN layers take word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.unit_type = unit_type\n",
    "        if self.unit_type == \"rnn\":\n",
    "            self.recurrent = nn.RNN(embedding_dim, hidden_dim,\n",
    "                                num_layers=num_layers, bidirectional=bidir,\n",
    "                                nonlinearity=\"tanh\", dropout=dropout, \n",
    "                                batch_first=True)\n",
    "        elif self.unit_type == \"gru\":\n",
    "            self.recurrent = nn.GRU(embedding_dim, hidden_dim,\n",
    "                                num_layers=num_layers, bidirectional=bidir,\n",
    "                                dropout=dropout, batch_first=True)\n",
    "        elif self.unit_type == \"lstm\":\n",
    "            self.recurrent = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                                num_layers=num_layers, bidirectional=bidir, \n",
    "                                dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # The linear layers that map from hidden state space to grounding space\n",
    "        self.hidden2action = nn.Linear(self.hidden_dim, action_size)\n",
    "        self.hidden2room = nn.Linear(self.hidden_dim, room_size)\n",
    "        self.hidden2object = nn.Linear(self.hidden_dim, object_size)\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        # Embed the sentence\n",
    "        embeds = self.word_embeddings(inp)\n",
    "\n",
    "        # Pass through the LSTM Module\n",
    "        rnn_out, _ = self.recurrent(embeds)\n",
    "\n",
    "        # Grab the final RNN output for each batch element\n",
    "        rnn_final = rnn_out[:,-1,:]\n",
    "\n",
    "        # Final Fully Connected Networks\n",
    "        action_scores = func.softmax(self.hidden2action(rnn_final), dim=1)\n",
    "        room_scores = func.softmax(self.hidden2room(rnn_final), dim=1)\n",
    "        object_scores = func.softmax(self.hidden2object(rnn_final), dim=1)\n",
    "\n",
    "        return action_scores, room_scores, object_scores\n",
    "\n",
    "\n",
    "# Create a sample network\n",
    "net = GroundingNetwork(action_size=len(act2i), room_size=len(room2i), object_size=len(obj2i), \n",
    "                       unit_type=\"rnn\", bidir=False)\n",
    "print(net)\n",
    "print(\"\")\n",
    "\n",
    "# Convert a sentence to a Torch Tensor of the word index sequence\n",
    "test_sentence = \"Go to the kitchen and find an apple.\"\n",
    "test_sequence = prepare_input_sequence(test_sentence, w2i)\n",
    "test_tensor = torch.LongTensor(test_sequence)\n",
    "print(\"Sentence: {}\".format(test_sentence))\n",
    "print(\"Word Sequence: {}\".format(test_sequence))\n",
    "print(\"\")\n",
    "\n",
    "# Run inference using the randomly initialized weights\n",
    "# (Everything should have ~equal probability since the model is not trained)\n",
    "with torch.no_grad():\n",
    "    act_scores, room_scores, obj_scores = net(test_tensor.view(1,-1))\n",
    "print(\"Action scores: {}\".format(act_scores.numpy()))\n",
    "print(\"Room scores: {}\".format(room_scores.numpy()))\n",
    "print(\"Object scores: {}\".format(obj_scores.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a Network\n",
    "\n",
    "Finally we get to train the RNN. Again, note that this will work only by passing individual inputs or batches with fixed-size sequences, as it makes the syntax simpler.\n",
    "\n",
    "If you want to use batches of data with variable-size sequences, you may want to look at how to configure a DataLoader to collate batches using the [`pad_sequence`](https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pad_sequence.html) function. I will again point you to [this tutorial by suzyahyah](https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 500, Average Loss -1.3309\n",
      "Epoch 1, Iteration 1000, Average Loss -2.0482\n",
      "Epoch 2, Iteration 1500, Average Loss -2.3074\n",
      "Epoch 2, Iteration 2000, Average Loss -2.5510\n",
      "Epoch 3, Iteration 2500, Average Loss -2.6508\n",
      "Epoch 3, Iteration 3000, Average Loss -2.6507\n",
      "Epoch 4, Iteration 3500, Average Loss -2.6617\n",
      "Epoch 4, Iteration 4000, Average Loss -2.6799\n",
      "Epoch 5, Iteration 4500, Average Loss -2.8141\n",
      "Epoch 5, Iteration 5000, Average Loss -2.9611\n",
      "Epoch 5, Iteration 5000, Average Loss -2.9611\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a new RNN (so it's easier to change options without scrolling up)\n",
    "# Try changing these options to see their effect\n",
    "net = GroundingNetwork(action_size=len(act2i), room_size=len(room2i), object_size=len(obj2i),\n",
    "                       hidden_dim=32, num_layers=2, unit_type=\"lstm\", bidir=True, dropout=0.25)\n",
    "                       \n",
    "# Learning parameters\n",
    "NUM_EPOCHS = 5      # Number of epochs\n",
    "LEARN_RATE = 0.005  # Learning rate\n",
    "ITER_WINDOW = 500   # Number of iterations to average loss for display\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARN_RATE)\n",
    "                             \n",
    "# Training loop\n",
    "i = 0\n",
    "loss_window = deque(maxlen=ITER_WINDOW)\n",
    "mean_losses = []\n",
    "iter_ticks = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for item in training_data:\n",
    "        # Clear gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # Run forward pass\n",
    "        (inp, tgt) = item\n",
    "        (action_scores, room_scores, object_scores) = net(inp.view(1,-1))\n",
    "        action_targets = tgt[0]\n",
    "        room_targets = tgt[1]\n",
    "        object_targets = tgt[2]\n",
    "\n",
    "        # Compute the loss, gradients, and update the parameters\n",
    "        loss = loss_function(action_scores, action_targets) + \\\n",
    "               loss_function(room_scores, room_targets) + \\\n",
    "               loss_function(object_scores, object_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add loss information for visualization at regular checkpoints\n",
    "        i += 1\n",
    "        loss_window.append(loss.detach().numpy())\n",
    "        iter_ticks.append(i)\n",
    "        mean_losses.append(np.mean(loss_window))\n",
    "        if i % ITER_WINDOW == 0:\n",
    "            print(\"Epoch {}, Iteration {}, Average Loss {:.4f}\".format(epoch+1, i, mean_losses[-1]))\n",
    "\n",
    "# Add loss information for the final iteration as well\n",
    "loss_window.append(loss.detach().numpy())\n",
    "iter_ticks.append(i)\n",
    "mean_losses.append(np.mean(loss_window))\n",
    "if i % ITER_WINDOW == 0:\n",
    "    print(\"Epoch {}, Iteration {}, Average Loss {:.4f}\".format(epoch+1, i, mean_losses[-1]))\n",
    "\n",
    "# Plot the training results\n",
    "plt.plot(iter_ticks, mean_losses)\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Avg. Loss ({} Steps)\".format(ITER_WINDOW))\n",
    "plt.grid(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Network on the Test Set\n",
    "\n",
    "Now we will use our trained network to run inference on the training and test sets. To do this, we have created a utility function.\n",
    "\n",
    "Then, we can use these predictions to evaluate our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 972/1000 (97.20%)\n",
      "Test Accuracy = 484/500 (96.80%)\n",
      "\n",
      "Command: throw away the water near the kitchen\n",
      "Action scores: ['0.000', '0.000', '0.000', '1.000']\n",
      "Room scores: ['0.000', '1.000', '0.000', '0.000']\n",
      "Object scores: ['1.000', '0.000', '0.000', '0.000']\n",
      "Prediction: ['store', 'kitchen', 'drink']\n",
      "\n",
      "Command: pick up some banana inside the bedroom\n",
      "Action scores: ['0.000', '1.000', '0.000', '0.000']\n",
      "Room scores: ['1.000', '0.000', '0.000', '0.000']\n",
      "Object scores: ['0.000', '1.000', '0.000', '0.000']\n",
      "Prediction: ['get', 'bedroom', 'fruit']\n",
      "\n",
      "Command: find the cookies by the bedroom\n",
      "Action scores: ['1.000', '0.000', '0.000', '0.000']\n",
      "Room scores: ['1.000', '0.000', '0.000', '0.000']\n",
      "Object scores: ['0.000', '0.000', '1.000', '0.000']\n",
      "Prediction: ['find', 'bedroom', 'snack']\n",
      "\n",
      "Command: bring the apple from the canteen\n",
      "Action scores: ['0.000', '1.000', '0.000', '0.000']\n",
      "Room scores: ['0.000', '1.000', '0.000', '0.000']\n",
      "Object scores: ['0.000', '1.000', '0.000', '0.000']\n",
      "Prediction: ['get', 'kitchen', 'fruit']\n",
      "\n",
      "Command: get me some crackers\n",
      "Action scores: ['0.002', '0.998', '0.000', '0.000']\n",
      "Room scores: ['0.000', '0.000', '0.000', '1.000']\n",
      "Object scores: ['0.000', '0.000', '1.000', '0.000']\n",
      "Prediction: ['get', 'unknown', 'snack']\n"
     ]
    }
   ],
   "source": [
    "def validate(net, data, word_to_ix, ix_to_word, action_to_ix, room_to_ix, object_to_ix, do_print=False):\n",
    "    \"\"\" Runs inference on every element of `data` and returns the predictions \"\"\" \n",
    "    num_correct = 0\n",
    "    idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in data:\n",
    "\n",
    "            # Evaluate the model\n",
    "            (inp, tgt) = item\n",
    "            inp = inp.view(1,-1)\n",
    "            (action_scores, room_scores, object_scores) = net(inp)\n",
    "\n",
    "            # Find the max scores and predicted output\n",
    "            tgt_list = tgt.tolist()                \n",
    "\n",
    "            for i in range(action_scores.size()[0]):\n",
    "\n",
    "                # Get predictions and indices\n",
    "                _,act_ind = action_scores[i].max(0)\n",
    "                _,room_ind = room_scores[i].max(0)\n",
    "                _,obj_ind = object_scores[i].max(0)\n",
    "                predicted_inds = (act_ind.item(),room_ind.item(),obj_ind.item())\n",
    "                predicted_output = [list(action_to_ix)[predicted_inds[0]],\n",
    "                                    list(room_to_ix)[predicted_inds[1]], \n",
    "                                    list(object_to_ix)[predicted_inds[2]]]\n",
    "                \n",
    "                # Get true grounding indices\n",
    "                true_inds = (tgt_list[0][i],\n",
    "                             tgt_list[1][i],\n",
    "                             tgt_list[2][i])\n",
    "                \n",
    "                # Tally up the total number of correct predictions\n",
    "                if predicted_inds == true_inds:\n",
    "                    num_correct += 1\n",
    "\n",
    "                # Print the output\n",
    "                if do_print:\n",
    "                    print(\"\")\n",
    "                    sentence = []\n",
    "                    sentence_length = inp.shape[1]\n",
    "                    for j in range(sentence_length):\n",
    "                        elem = inp[i,j].item()\n",
    "                        sentence.append(ix_to_word[elem])\n",
    "                    print(\"Command: {}\".format(\" \".join(sentence)))\n",
    "                    action_list = [\"%.3f\"%item for item in action_scores[i].tolist()]\n",
    "                    print(\"Action scores: {}\".format(action_list))\n",
    "                    room_list = [\"%.3f\"%item for item in room_scores[i].tolist()]\n",
    "                    print(\"Room scores: {}\".format(room_list))\n",
    "                    object_list = [\"%.3f\"%item for item in object_scores[i].tolist()]\n",
    "                    print(\"Object scores: {}\".format(object_list))\n",
    "                    print(\"Prediction: {}\".format(predicted_output))\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "    return predicted_output, num_correct\n",
    "\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "predicted_train, num_correct_train = validate(net, training_data, w2i, i2w, act2i, room2i, obj2i)\n",
    "predicted_test, num_correct_test = validate(net, test_data, w2i, i2w, act2i, room2i, obj2i)\n",
    "train_acc = 100*num_correct_train/len(training_data)\n",
    "print(\"Training Accuracy = {}/{} ({:.2f}%)\".format(num_correct_train, len(training_data), train_acc))\n",
    "test_acc = 100*num_correct_test/len(test_data)\n",
    "print(\"Test Accuracy = {}/{} ({:.2f}%)\".format(num_correct_test, len(test_data), test_acc))\n",
    "\n",
    "# Print on a few examples\n",
    "num_samples = 5\n",
    "sample_indices = np.random.choice(len(test_data), num_samples)\n",
    "sample_data = [test_data.__getitem__(i) for i in sample_indices]\n",
    "(sample_pred, sample_correct) = validate(net, sample_data, w2i, i2w, act2i, room2i, obj2i, do_print=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('intro-nlp': conda)",
   "language": "python",
   "name": "python361064bitintronlpconda61e1afdce515499c9770b8779f7d77e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
